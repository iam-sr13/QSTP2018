{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QSTP Image Recognition with Deep Learning\n",
    "\n",
    "Name: Shriraj Sawant\n",
    "\n",
    "Contact: 9923690913\n",
    "\n",
    "Email: sr.official@hotmail.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500, Loss: 0.4102, Accuracy: 84.89\n",
      "Iter: 1000, Loss: 0.43, Accuracy: 87.48\n",
      "Iter: 1500, Loss: 0.3595, Accuracy: 88.81\n",
      "Iter: 2000, Loss: 0.4474, Accuracy: 89.3\n",
      "Iter: 2500, Loss: 0.4046, Accuracy: 90.13\n",
      "Iter: 3000, Loss: 0.3612, Accuracy: 90.33\n",
      "Iter: 3500, Loss: 0.2431, Accuracy: 90.71\n",
      "Iter: 4000, Loss: 0.3065, Accuracy: 90.81\n",
      "Iter: 4500, Loss: 0.3988, Accuracy: 91.29\n",
      "Iter: 5000, Loss: 0.1271, Accuracy: 91.62\n",
      "Iter: 5500, Loss: 0.183, Accuracy: 91.64\n",
      "Iter: 6000, Loss: 0.147, Accuracy: 91.56\n",
      "Iter: 6500, Loss: 0.341, Accuracy: 91.76\n",
      "Iter: 7000, Loss: 0.264, Accuracy: 92.16\n",
      "Iter: 7500, Loss: 0.1871, Accuracy: 91.7\n",
      "Iter: 8000, Loss: 0.2085, Accuracy: 92.33\n",
      "Iter: 8500, Loss: 0.1484, Accuracy: 92.05\n",
      "Iter: 9000, Loss: 0.1545, Accuracy: 92.37\n",
      "Iter: 9500, Loss: 0.2213, Accuracy: 92.34\n",
      "Iter: 10000, Loss: 0.1257, Accuracy: 92.4\n",
      "Iter: 10500, Loss: 0.1814, Accuracy: 92.41\n",
      "Iter: 11000, Loss: 0.2549, Accuracy: 92.28\n",
      "Iter: 11500, Loss: 0.1861, Accuracy: 92.39\n",
      "Iter: 12000, Loss: 0.1386, Accuracy: 92.81\n",
      "Iter: 12500, Loss: 0.3641, Accuracy: 92.75\n",
      "Iter: 13000, Loss: 0.1395, Accuracy: 92.55\n",
      "Iter: 13500, Loss: 0.1711, Accuracy: 92.46\n",
      "Iter: 14000, Loss: 0.1362, Accuracy: 92.74\n",
      "Iter: 14500, Loss: 0.1167, Accuracy: 92.38\n",
      "Iter: 15000, Loss: 0.1612, Accuracy: 92.59\n",
      "Iter: 15500, Loss: 0.1051, Accuracy: 92.78\n",
      "Iter: 16000, Loss: 0.08355, Accuracy: 92.77\n",
      "Iter: 16500, Loss: 0.1102, Accuracy: 92.9\n",
      "Iter: 17000, Loss: 0.1079, Accuracy: 92.88\n",
      "Iter: 17500, Loss: 0.06937, Accuracy: 92.87\n",
      "Iter: 18000, Loss: 0.1206, Accuracy: 92.89\n",
      "Iter: 18500, Loss: 0.1099, Accuracy: 92.99\n",
      "Iter: 19000, Loss: 0.1405, Accuracy: 92.83\n",
      "Iter: 19500, Loss: 0.06131, Accuracy: 93.05\n",
      "Iter: 20000, Loss: 0.1188, Accuracy: 93.02\n",
      "Iter: 20500, Loss: 0.1646, Accuracy: 93.06\n",
      "Iter: 21000, Loss: 0.0516, Accuracy: 92.9\n",
      "Iter: 21500, Loss: 0.1091, Accuracy: 92.97\n",
      "Iter: 22000, Loss: 0.08711, Accuracy: 92.88\n",
      "Iter: 22500, Loss: 0.1065, Accuracy: 93.09\n",
      "Iter: 23000, Loss: 0.07493, Accuracy: 93.06\n",
      "Iter: 23500, Loss: 0.1317, Accuracy: 92.97\n",
      "Iter: 24000, Loss: 0.09784, Accuracy: 93.2\n",
      "Training Set Accuracy: 99.17, Test Set Accuracy: 93.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms as tforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from mnist import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#Creating Dataset class for loading FashionMNIST dataset directly from given idx3-ubyte.gz format\n",
    "class FashionMNIST(Dataset):\n",
    "    \"\"\" Fashion MNIST Dataset \"\"\"\n",
    "    def __init__(self, root='.', train=True, transform=None):\n",
    "        \"\"\"\n",
    "        Args:            \n",
    "            root (string): Directory with all the dataset in .gz form.\n",
    "            train (boolean): Choice for training or test dataset. By default loads training dataset.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.root = root        \n",
    "        self.transform = transform\n",
    "        self.images = None\n",
    "        self.labels = None        \n",
    "        if train:\n",
    "            self.images, self.labels = MNIST(path=root, return_type='numpy', gz=True).load_training()\n",
    "        else:\n",
    "            self.images, self.labels = MNIST(path=root, return_type='numpy', gz=True).load_testing()        \n",
    "        self.mean = self.images.mean()\n",
    "        self.std = self.images.std()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        normTransform=tforms.Compose([tforms.ToTensor(), tforms.Normalize(mean=[self.mean], std=[self.std])])\n",
    "        \n",
    "        image = self.images[idx].astype('float32').reshape(28,28,1)\n",
    "        image = normTransform(image)\n",
    "        label = torch.tensor(self.labels[idx].item())\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "    \n",
    "train_dataset = FashionMNIST(root='fashion-mnist-master/data/fashion', train=True)\n",
    "test_dataset = FashionMNIST(root='fashion-mnist-master/data/fashion', train=False)\n",
    "\n",
    "batch_size = 100\n",
    "n_iters = 24000\n",
    "epochs = int(n_iters*batch_size/len(train_dataset))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "#Deep Neural Network Architecture for training the model\n",
    "class CNNmodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNmodel, self).__init__()             \n",
    "        \n",
    "        #self.bn1 = nn.BatchNorm2d(1)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
    "        self.drop1 = nn.Dropout2d(0.1)\n",
    "        self.ac1 = nn.ReLU()        \n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.drop2 = nn.Dropout2d(0.1)\n",
    "        self.ac2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)  \n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2)\n",
    "        self.drop3 = nn.Dropout2d(0.1)\n",
    "        self.ac3 = nn.ReLU()        \n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.drop4 = nn.Dropout2d(0.1)\n",
    "        self.ac4 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2)         \n",
    "        \n",
    "        #self.bno = nn.BatchNorm2d(128)\n",
    "        self.fc1 = nn.Linear(128*7*7, 100)\n",
    "        self.bno = nn.BatchNorm1d(100)\n",
    "        self.dropo = nn.Dropout(0.5)\n",
    "        self.aco = nn.ReLU()\n",
    "        self.opl = nn.Linear(100, 10)\n",
    "        \n",
    "        nn.init.kaiming_normal_(self.conv1.weight, nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.conv2.weight, nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.conv3.weight, nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.conv4.weight, nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.opl.weight, nonlinearity='relu')        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        \n",
    "        out = self.conv1(out)\n",
    "        out = self.drop1(out)\n",
    "        out = self.ac1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.drop2(out)\n",
    "        out = self.ac2(out)\n",
    "        out = self.pool2(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.drop3(out)\n",
    "        out = self.ac3(out)\n",
    "        \n",
    "        out = self.conv4(out)\n",
    "        out = self.bn4(out)\n",
    "        out = self.drop4(out)\n",
    "        out = self.ac4(out)\n",
    "        out = self.pool4(out)\n",
    "        \n",
    "        #out = self.bno(out)\n",
    "        out = out.view(out.size(0), -1) \n",
    "        out = self.fc1(out)\n",
    "        out = self.bno(out)\n",
    "        out = self.dropo(out)\n",
    "        out = self.aco(out)\n",
    "        out = self.opl(out)\n",
    "        return out\n",
    "    \n",
    "my_model = CNNmodel()\n",
    "my_model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(my_model.parameters(), lr = 0.05)\n",
    "\n",
    "#Training the model\n",
    "itr = 0\n",
    "for epoch in range(epochs):\n",
    "    for images, labels in train_loader:\n",
    "        images.requires_grad_()\n",
    "        labels.requires_grad_()\n",
    "        images=images.cuda()\n",
    "        labels=labels.cuda()\n",
    "        \n",
    "        my_model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = my_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        itr+=1\n",
    "        if itr%500 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            my_model.eval()\n",
    "            \n",
    "            for images, labels in test_loader:  \n",
    "                images=images.cuda()\n",
    "                outputs = my_model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                total+=labels.size(0)\n",
    "                correct+= (predicted.cpu() == labels.cpu()).sum()\n",
    "    \n",
    "            acc = 100*float(correct)/total\n",
    "            print(\"Iter: {}, Loss: {:.4}, Accuracy: {:.4}\".format(itr, loss, acc))    \n",
    "\n",
    "my_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:  \n",
    "    images=images.cuda()\n",
    "    outputs = my_model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)                \n",
    "    total+=labels.size(0)\n",
    "    correct+= (predicted.cpu() == labels.cpu()).sum()    \n",
    "test_acc = 100*float(correct)/total\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in train_loader:  \n",
    "    images=images.cuda()\n",
    "    outputs = my_model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)                \n",
    "    total+=labels.size(0)\n",
    "    correct+= (predicted.cpu() == labels.cpu()).sum()  \n",
    "train_acc = 100*float(correct)/total  \n",
    "\n",
    "print(\"Training Set Accuracy: {:.4}, Test Set Accuracy: {:.4}\".format(train_acc, test_acc))    \n",
    "            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shriraj\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:193: UserWarning: Couldn't retrieve source code for container of type CNNmodel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(my_model,'cnn_93.2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
